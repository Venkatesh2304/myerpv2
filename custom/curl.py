import argparse
import json
import re
from requests import Request,Session
from collections import namedtuple
from urllib.parse import urlparse
import subprocess 
import json
from pathlib import Path
import os
import platform
from all_curls import CurlRequest
import all_curls
import copy


def is_url(url: str) -> bool:
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except Exception:
        return False

def parse_file(fname,rename_request_to) -> str :
    if platform.system() == 'Linux' :
       curl_code = subprocess.run([f"cat {fname} | curlconverter -"],capture_output=True,shell="bash")
    else : 
        curl_code = subprocess.run(f"type {fname} | curlconverter -",capture_output=True,shell=True)    
    curl_code = curl_code.stdout.decode('ascii') 
    for x,y in [["response = requests.post(",f"{rename_request_to} = CurlRequest('POST',"],
                ["response = requests.get(",f"{rename_request_to} = CurlRequest('GET',"],
                ["response = requests.head(",f"{rename_request_to} = CurlRequest('HEAD',"]] : 
        curl_code = curl_code.replace(x,y)
    return curl_code
 
def parse(command:str) : 
    result = subprocess.run(['curlconverter', '--language', 'json', '-'], text=True, input=command, capture_output=True)
    return json.loads(result.stdout)

def interpret_all_curls() : 
    imports = """import requests
from requests import Request, Session
class CurlRequest(Request) : 
      def send(self,s = None) :  
          if s is None : 
             print("Request sent via new created dummy session")
             return Session().send( self.prepare() )
          else : 
             self.cookies = s.cookies.get_dict()
             return s.send( self.prepare() )"""
    
    code_lines = [imports]
    fldrs = [Path(os.getcwd()), Path(__file__).parent]
    for fldr in fldrs:
        if os.path.exists(fldr / "curl"):
            for root, dirs, files in os.walk(fldr / "curl"):
                for file in files:
                    fname = os.path.join(root, file)
                    key = fname.split("curl/")[-1].replace(".txt", "")
                    rename_request_to = key.replace("/", "_")
                    curl_code = parse_file(fname,rename_request_to)
                    code_lines += curl_code.split("\n")[2:]
    with open("all_curls.py","w+") as f : 
        f.write("# This file is auto-generated by the script\n")
        f.write("# Do not edit this file manually\n")
        f.write("\n".join(code_lines))

def get_curl(key, base_path=None) -> CurlRequest:
    r = all_curls.__dict__.get(key.replace("/", "_"))
    r = copy.deepcopy(r)
    r.headers = {
        header: r.headers[header]
        for header in ["accept", "accept-language", "content-type", "User-Agent"]
        if header in r.headers
    }
    return r
    
def curl_replace(pat,replaces,str) : 
    pat = re.compile(pat)
    replace_pat = ""
    for i in range(pat.groups) : 
        replace_pat += (f"\{i+1}%%%" + replaces[i])
    return re.sub(pat,replace_pat,str).replace("%%%","") 
      
if __name__ == "__main__" : 


    ParsedCommand = namedtuple(
        "ParsedCommand",
        [
            "method",
            "url",
            "auth",
            "cookies",
            "data",
            "json",
            "header",
            "verify",
        ],
    )

    parser = argparse.ArgumentParser()

    parser.add_argument("command")
    parser.add_argument("url")
    parser.add_argument("-A", "--user-agent")
    parser.add_argument("-I", "--head")
    parser.add_argument("-H", "--header", action="append", default=[])
    parser.add_argument("-b", "--cookie", action="append", default=[])
    parser.add_argument("-d", "--data", "--data-ascii", "--data-binary", "--data-raw", default=None)
    parser.add_argument("-k", "--insecure", action="store_false")
    parser.add_argument("-u", "--user", default=())
    parser.add_argument("-X", "--request", default="")
